{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/george/miniconda3/envs/multimodal-hybrid-parsing-2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "from docling.document_converter import (\n",
    "    DocumentConverter,\n",
    "    PdfFormatOption,\n",
    "    WordFormatOption,\n",
    "    PowerpointFormatOption\n",
    ")\n",
    "from docling.datamodel.base_models import InputFormat, DocumentStream\n",
    "from docling.datamodel.pipeline_options import (\n",
    "    AcceleratorDevice,\n",
    "    AcceleratorOptions, \n",
    "    PdfPipelineOptions,\n",
    ")\n",
    "from docling_core.types.doc import PictureItem\n",
    "from docling.pipeline.simple_pipeline import SimplePipeline\n",
    "import io\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentProcessor:\n",
    "    def __init__(self):\n",
    "        self.pipeline_options = PdfPipelineOptions()\n",
    "        self.pipeline_options.images_scale = 150/72.0\n",
    "        self.pipeline_options.generate_page_images = True\n",
    "        self.pipeline_options.generate_picture_images = True\n",
    "        self.pipeline_options.do_formula_enrichment = True\n",
    "        self.pipeline_options.accelerator_options = AcceleratorOptions(\n",
    "            num_threads=8,\n",
    "            device=AcceleratorDevice.CUDA\n",
    "        )\n",
    "        self.pipeline_options.do_picture_description = False\n",
    "        self.converter = DocumentConverter(\n",
    "            allowed_formats=[\n",
    "                InputFormat.PDF,\n",
    "                InputFormat.PPTX,\n",
    "                InputFormat.DOCX\n",
    "            ],\n",
    "            format_options={\n",
    "                InputFormat.PDF: PdfFormatOption(\n",
    "                    pipeline_options=self.pipeline_options\n",
    "                ),\n",
    "                InputFormat.PPTX: PowerpointFormatOption(\n",
    "                    pipeline_cls=SimplePipeline\n",
    "                ),\n",
    "                InputFormat.DOCX: WordFormatOption(\n",
    "                    pipeline_cls=SimplePipeline\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def __call__(\n",
    "        self, \n",
    "        base64_content: str\n",
    "    ) -> Tuple[List[str], List[str], List[int]]:\n",
    "        # Decode base64 content to bytes\n",
    "        doc_content = base64.b64decode(base64_content)\n",
    "\n",
    "        # Create BytesIO object and DocumentStream\n",
    "        doc_stream = io.BytesIO(doc_content)\n",
    "        source = DocumentStream(name=\"doc\", stream=doc_stream)\n",
    "\n",
    "        # Convert using DocumentStream\n",
    "        result = self.converter.convert(source)\n",
    "\n",
    "        extracted_images = []\n",
    "        markdown_pages = []\n",
    "        pages_with_images = []\n",
    "        # Extract images\n",
    "        for element, _level in result.document.iterate_items():\n",
    "            if isinstance(element, PictureItem):\n",
    "                # For DOCX files, we'll use a default page number of 1 since the number of pages aren't properly registered (Docling bug)\n",
    "                page_no = element.prov[0].page_no if element.prov else 1\n",
    "                if hasattr(element, 'image') and element.image is not None:\n",
    "                    extracted_images.append(str(element.image.uri))\n",
    "                    pages_with_images.append(page_no)\n",
    "        # For DOCX files, we need to handle the case where num_pages() returns 0\n",
    "        if result.document.num_pages() == 0:\n",
    "            # Get markdown for the entire document as a single page\n",
    "            full_md = result.document.export_to_markdown()\n",
    "            markdown_pages.append(full_md)\n",
    "        else:\n",
    "            # Process markdown pages normally for PDF and PPTX\n",
    "            for page in range(result.document.num_pages()):\n",
    "                page_no = page + 1\n",
    "                page_md = result.document.export_to_markdown(page_no=page_no)\n",
    "                markdown_pages.append(page_md)\n",
    "        return markdown_pages, extracted_images, pages_with_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_processor = DocumentProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: source file could not be loaded\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "def convert_file(input_path, output_format):\n",
    "    output_dir = os.path.dirname(input_path)\n",
    "    command = [\n",
    "        \"soffice\",\n",
    "        \"--headless\",\n",
    "        \"--convert-to\", output_format,\n",
    "        input_path,\n",
    "        \"--outdir\", output_dir\n",
    "    ]\n",
    "    subprocess.run(command, check=True)\n",
    "\n",
    "# Convert a .doc file to .docx\n",
    "convert_file(\"samples/sample.doc\", \"docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:application/vnd.openxmlformats-officedocument.presentationml.presentation;base64,UEsDBBQABgAIAA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data:application/vnd.openxmlformats-officedocument.presentationml.presentation;base64'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "import mimetypes\n",
    "\n",
    "file_path = \"samples/sample.pptx\"\n",
    "\n",
    "# Determine MIME type based on the file extension\n",
    "mime_type, _ = mimetypes.guess_type(file_path)\n",
    "\n",
    "with open(file_path, 'rb') as file:\n",
    "    encoded_string = base64.b64encode(file.read()).decode('utf-8')\n",
    "\n",
    "# Add the MIME type prefix\n",
    "base64_string = f\"data:{mime_type};base64,{encoded_string}\"\n",
    "\n",
    "print(base64_string[:100])\n",
    "\n",
    "prefix = base64_string.split(',')[0]\n",
    "\n",
    "if prefix == \"data:application/vnd.openxmlformats-officedocument.presentationml.presentation;base64\":\n",
    "    convert_file(file_path, \"pptx\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_pages, extracted_images, pages_with_images = doc_processor(base64_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n\".join(markdown_pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import hashlib\n",
    "\n",
    "def get_image_hash(image):\n",
    "    \"\"\"Generate a hash for a PIL image.\"\"\"\n",
    "    return hashlib.md5(image.tobytes()).hexdigest()\n",
    "\n",
    "def get_unique_images_with_indices(images):\n",
    "    \"\"\"Return unique images and their original indices.\"\"\"\n",
    "    seen_hashes = {}\n",
    "    unique_images = []\n",
    "    unique_indices = []\n",
    "    \n",
    "    for idx, img in enumerate(images):\n",
    "        img_hash = get_image_hash(img)\n",
    "        if img_hash not in seen_hashes:\n",
    "            seen_hashes[img_hash] = len(unique_images)\n",
    "            unique_images.append(img)\n",
    "        unique_indices.append(seen_hashes[img_hash])\n",
    "    \n",
    "    return unique_images, unique_indices\n",
    "\n",
    "# Example usage:\n",
    "# list_of_pil_images = [...]\n",
    "unique_images, unique_indices = get_unique_images_with_indices(extracted_images)\n",
    "\n",
    "# Process the unique images\n",
    "processed_results = [img.height for img in unique_images]  # Replace with your actual processing\n",
    "\n",
    "# Map the results back to the original list\n",
    "original_results = [processed_results[i] for i in unique_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal-hybrid-parsing-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
