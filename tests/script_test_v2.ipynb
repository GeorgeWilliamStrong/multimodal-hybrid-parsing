{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/george/miniconda3/envs/multimodal-hybrid-parsing-2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Optional, Union,Tuple\n",
    "from PIL import Image\n",
    "from docling.document_converter import (\n",
    "    DocumentConverter,\n",
    "    PdfFormatOption,\n",
    "    WordFormatOption,\n",
    "    PowerpointFormatOption\n",
    ")\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import (\n",
    "    AcceleratorDevice,\n",
    "    AcceleratorOptions, \n",
    "    PdfPipelineOptions,\n",
    "    PipelineOptions\n",
    ")\n",
    "from docling_core.types.doc import PictureItem\n",
    "from docling.pipeline.simple_pipeline import SimplePipeline\n",
    "from docling.backend.mspowerpoint_backend import MsPowerpointDocumentBackend\n",
    "from docling.backend.msword_backend import MsWordDocumentBackend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentProcessor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        device: Optional[str] = None,\n",
    "        num_threads: int = 8\n",
    "    ):\n",
    "        device_map = {\n",
    "            \"cuda\": AcceleratorDevice.CUDA,\n",
    "            \"mps\": AcceleratorDevice.MPS,\n",
    "            \"cpu\": AcceleratorDevice.CPU,\n",
    "            \"auto\": AcceleratorDevice.AUTO,\n",
    "        }\n",
    "        self.device = device or \"auto\"\n",
    "        if self.device not in device_map:\n",
    "            msg = f\"Invalid device '{device}'. Must be one of: {list(device_map.keys())}\"\n",
    "            raise ValueError(msg)\n",
    "        # Configure pipeline options\n",
    "        self.pipeline_options = PdfPipelineOptions()\n",
    "        self.pipeline_options.images_scale = 150/72.0\n",
    "        self.pipeline_options.generate_page_images = True\n",
    "        self.pipeline_options.generate_picture_images = True\n",
    "        self.pipeline_options.do_formula_enrichment = True\n",
    "        self.pipeline_options.accelerator_options = AcceleratorOptions(\n",
    "            num_threads=num_threads,\n",
    "            device=device_map[self.device]\n",
    "        )\n",
    "        self.pipeline_options.do_picture_description = False\n",
    "        self.converter = DocumentConverter(\n",
    "            allowed_formats=[\n",
    "                InputFormat.PDF,\n",
    "                InputFormat.PPTX,\n",
    "                InputFormat.DOCX\n",
    "            ],\n",
    "            format_options={\n",
    "                InputFormat.PDF: PdfFormatOption(\n",
    "                    pipeline_options=self.pipeline_options\n",
    "                ),\n",
    "                InputFormat.PPTX: PowerpointFormatOption(\n",
    "                    pipeline_cls=SimplePipeline\n",
    "                ),\n",
    "                InputFormat.DOCX: WordFormatOption(\n",
    "                    pipeline_cls=SimplePipeline\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "    def __call__(\n",
    "        self,\n",
    "        file_path: Union[str, Path]\n",
    "    ) -> Tuple[List[str], List[Image.Image], List[int]]:\n",
    "        file_path = Path(file_path) if isinstance(file_path, str) else file_path\n",
    "        result = self.converter.convert(file_path)\n",
    "        extracted_images = []\n",
    "        markdown_pages = []\n",
    "        pages_with_images = []\n",
    "        # Extract images\n",
    "        for element, _level in result.document.iterate_items():\n",
    "            if isinstance(element, PictureItem):\n",
    "                # For DOCX files, we'll use a default page number of 1 since the number of pages aren't properly registered (Docling bug)\n",
    "                page_no = element.prov[0].page_no if element.prov else 1\n",
    "                if hasattr(element, 'image') and element.image is not None:\n",
    "                    extracted_images.append(element.image.pil_image)\n",
    "                    pages_with_images.append(page_no)\n",
    "        # For DOCX files, we need to handle the case where num_pages() returns 0\n",
    "        if result.document.num_pages() == 0:\n",
    "            # Get markdown for the entire document as a single page\n",
    "            full_md = result.document.export_to_markdown()\n",
    "            markdown_pages.append(full_md)\n",
    "        else:\n",
    "            # Process markdown pages normally for PDF and PPTX\n",
    "            for page in range(result.document.num_pages()):\n",
    "                page_no = page + 1\n",
    "                page_md = result.document.export_to_markdown(page_no=page_no)\n",
    "                markdown_pages.append(page_md)\n",
    "        return markdown_pages, extracted_images, pages_with_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_processor = DocumentProcessor(\n",
    "    device=\"cuda\",\n",
    "    num_threads=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: source file could not be loaded\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "def convert_file(input_path, output_format):\n",
    "    output_dir = os.path.dirname(input_path)\n",
    "    command = [\n",
    "        \"soffice\",\n",
    "        \"--headless\",\n",
    "        \"--convert-to\", output_format,\n",
    "        input_path,\n",
    "        \"--outdir\", output_dir\n",
    "    ]\n",
    "    subprocess.run(command, check=True)\n",
    "\n",
    "# Convert a .doc file to .docx\n",
    "convert_file(\"samples/sample.doc\", \"docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_pages, extracted_images, pages_with_images = doc_processor(\"samples/sample.pptx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harnessing High Frequency Data To Inform Development and Humanitarian Interventions\n",
      "\n",
      "Christopher B. Barrett\n",
      "\n",
      "Keynote address to the World Bank conference\n",
      "\n",
      "The Pulse of Progress: Harnessing High-Frequency Survey Data for Development Research in the Polycrisis Era\n",
      "\n",
      "Washington, DC\n",
      "\n",
      "December 17, 2024\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Statistically representative observational data essential for accurate descriptive/predictive analysis. Often useful for inferential analysis.\n",
      "\n",
      "World Bank established LSMS &gt;40 years ago for comparable measurement of living standards defined broadly. With improved measurement came improved analysis. \n",
      "\n",
      "\t\t\t\t– Angus Deaton 1997 (and 2018)\n",
      "\n",
      "“To direct scarce resources to where they can do the greatest good, actions must be guided by reliable information … Measurement drives diagnosis and response. ” \n",
      "\n",
      "\t\t\t\t– Barrett (Science 2010)\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Why national survey data?\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Living standards are dynamic. A solid understanding of dynamic living standards requires HFL data.\n",
      "\n",
      "1. Differentiating chronic vs. transitory state (poverty/food insecurity/ill health) matters fundamentally to policy design and evaluation. \n",
      "\n",
      "2. Seasonality looms large for the poor (esp. rural poor). Surveys every few years either miss seasonality or create seasonal mismatch issues in intertemporal comparison. \n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Why high-frequency longitudinal (HFL) national survey data?\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Source: Barrett &amp; Headey (IFPRI 2014) using data from Bloem et al. (HKI 2003)\n",
      "\n",
      "Child wasting in Bangladesh\n",
      "\n",
      "3. Dynamics introduce risk and uncertainty. It’s hard to understand human behavior and well-being without explicitly considering risk. \n",
      "\n",
      "- Risk aversion and defensive actions/investments\n",
      "- Non-stationarity and shocks\n",
      "- FE estimators –true intertemporal change; time invariant unobservables.\n",
      "- Improve external validity – Rosenzweig &amp; Udry (REStudies 2020)\n",
      "\n",
      "\t▪ moments beyond the mean matter to behavior and well-being.\n",
      "\n",
      "\t▪ inference commonly assumes stationary DGPs\n",
      "\n",
      "4. Improved inference about what causes change in living standards. \n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Why high-frequency longitudinal (HFL) national survey data?\n",
      "\n",
      "HFL data esp. important amid polycrisis. Multivariate risks growing: weather, conflict, prices, pandemics, etc. Solid inference around effective interventions crucial. Must parse chronic/seasonal/transitory effects of shocks.\n",
      "\n",
      "Distinction b/n s-run humanitarian and longer-run development interventions is increasingly blurred,       esp. in low-income settings. \n",
      "\n",
      "Hence attention to ‘resilience’ = shock-proofing continuous improvement in living standards.\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Polycrisis era\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Polycrisis, poverty traps, and resilience\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "poverty line\n",
      "\n",
      "Poverty traps increasingly understood as arising due to catastrophic risk exposure and/or the experience of catastrophic shocks. Reasonable theory exists, rooting resilience in living standards.\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "“our empirical understanding of development resilience in developing countries remains remarkably limited, primarily because of data shortcomings. … [The world needs] a multicountry system of high-frequency, long-term sentinel sites in the world’s most vulnerable (and largely rural) regions. … In an increasingly volatile world, good data are essential. Such data will help the global community build development resilience and eliminate hunger, extreme poverty, and vulnerability in the generation ahead.”\n",
      "\n",
      "HFL survey data especially important for studying resilience. \n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Yet very scarce. Scoping review of ‘resilience’ studies 2008-2020 found just 16% used panel data at all, much less HF!        (Barrett et al. WD 2021)\n",
      "\n",
      "Resilience measurement\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Resilience – like poverty, food security, women’s empowerment – is a latent variable … inherently hard to measure. Takes time to create/validate good measures of latent variables. Not yet there for resilience measurement.  \n",
      "\n",
      "Core issues: \n",
      "\n",
      "1. Interventions aim to ‘build resilience’, thus measures must allow resilience to be a dependent variable and to carry normative implications (e.g., monotonicity). \n",
      "2. Must work with multiple perils, given multivariate risk exposure.\n",
      "3. Must be decomposable since subpopulations may be heterogeneous.\n",
      "4. Given pronounced behavioral response to risk, must account for ex ante risk exposure not just ex post experience of shocks. \n",
      "5. Measures remain contested, imprecise, and inconsistent (Upton, Cissé &amp; Barrett Ag Econ 2016; Cissé &amp; Barrett JDE 2018; Barrett et al. WD 2021; Upton, Constenla-Villoslada &amp; Barrett JDE 2022)\n",
      "\n",
      "More and better resilience measurement research is needed.\n",
      "\n",
      "Resilience measurement\n",
      "\n",
      "The dearth of HFL socioeconomic survey data motivates enthusiasm for HFL geospatial data and ML algorithms to generate nowcasts/forecasts:\n",
      "\n",
      "“ a given African household will appear in a household well-being survey less than once every 1000 years” – Yeh et al. (Nature Communications 2020)\n",
      "\n",
      "Machine learning is indeed very promising, esp. for data fusion. \n",
      "\n",
      "(Yeh et al. NC 2020; McBride et al. AEPP 2022; Gualavisi &amp; Newhouse WBER 2024; Newhouse CSAB 2024)\n",
      "\n",
      "Example: spatial imagery + survey data permit pixel-scale wealth predictions at scale and downstream targeting. (Yeh et al. NC 2020, Figs 5-6 below)\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Benefits/Limits to Machine Learning\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "But HFL EO data complement, not substitute, for HFL SE data. Opportunities arising from ML and VHR/HF geospatial data boost need for HFL SE data.\n",
      "\n",
      "2. ML models need lots of good, reasonably current training data, ideally HFL SE data. Nonstationarity is a fundamental challenge, even to nowcasting. (Browne et al. PLoS ONE 2021; Constenla et al. in review; Tennant et al. in review).\n",
      "3. Prone to atheoretic modeling (McBride et al. AEPP 2022)\n",
      "4. Frequent, large bias – focus on OOS predictive skill overall. Misses significant spatial/livelihood heterogeneity, esp. related to unobservables and non-classical measurement error. (Ru et al. in review; Tennant et al. in review)\n",
      "5. Reproducibility harder than conventional econometric/statistical work. \n",
      "6. Often too technical and high-cost for operational agencies.\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Benefits/Limits to Machine Learning\n",
      "\n",
      "Rapid response ≠ researchers’ comparative advantage. We must improve our ability to respond to sudden changes. \n",
      "\n",
      "HFL SE survey data can not only: \n",
      "\n",
      "- improve ability to describe dynamics and risk\n",
      "- do better inference \n",
      "- add value to HFL geospatial data and ML\n",
      "\n",
      "HFL SE survey data can also enable analytical tasks that researchers undersupply currently.\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "What role for HFL survey data in polycrisis era?\n",
      "\n",
      "Use to design interventions that can build resilience. \n",
      "\n",
      "Example: index-based livestock insurance (IBLI)\n",
      "\n",
      "- HFL survey data enabled original IBLI design and piloting. (Chantarat et al. JRI 2013)\n",
      "- Enabled quasi-experimental comparison of IBLI vs. cash transfers. (Jensen et al. JDE 2017)\n",
      "- End result: IBLI scaled from pilot in small parts of 2 countries to broader use in 4 (and growing: Kenya Livestock Insurance Program, DRIVE).  ~600K people covered to date, expected/targeted &gt;1.5M by end-2025. \n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Pilot areas\n",
      "\n",
      "What role for HFL survey data in polycrisis era?\n",
      "\n",
      "Use for early warning and geographic targeting\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "What role for HFL survey data in polycrisis era?\n",
      "\n",
      "Most empirical economic analysis inherently backward looking; policy advice is forward-looking. HFL survey data allow for (i) rapid updating, (ii) nowcasting/forecasting for early warning and geographic targeting. High value of high frequency sentinel site data (Constenla et al. in review).\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "In polycrisis era, HFL survey data are more valuable than ever. Help answer policymakers’ questions in face of growing risk and shocks: \n",
      "\n",
      "- What gains from emergency preparedness? Behavioral responses to risk/shocks measured right.\n",
      "- What benefits from response to shocks? Transitory vs. seasonal vs. chronic and possibility of poverty traps. Inference using ‘within’ variation.\n",
      "- Where and when to respond? Nowcasting/forecasting maps\n",
      "- How to customized bundled responses? Sufficient variation in sites to identify heterogeneous and interaction effects. \n",
      "\n",
      "- Which tool(s) to use? More A/B testing, less H0=0 testing. Test under varied states of nature.\n",
      "\n",
      "Researchers have lots to do to help build resilience to polycrisis!\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Why high-frequency longitudinal (HFL) national survey data?\n",
      "\n",
      "Thank you for your time and interest!\n",
      "\n",
      "Follow-up questions/comments? \n",
      "\n",
      "Email me: cbb2@cornell.edu\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Thank you\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n\".join(markdown_pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import hashlib\n",
    "\n",
    "def get_image_hash(image):\n",
    "    \"\"\"Generate a hash for a PIL image.\"\"\"\n",
    "    return hashlib.md5(image.tobytes()).hexdigest()\n",
    "\n",
    "def get_unique_images_with_indices(images):\n",
    "    \"\"\"Return unique images and their original indices.\"\"\"\n",
    "    seen_hashes = {}\n",
    "    unique_images = []\n",
    "    unique_indices = []\n",
    "    \n",
    "    for idx, img in enumerate(images):\n",
    "        img_hash = get_image_hash(img)\n",
    "        if img_hash not in seen_hashes:\n",
    "            seen_hashes[img_hash] = len(unique_images)\n",
    "            unique_images.append(img)\n",
    "        unique_indices.append(seen_hashes[img_hash])\n",
    "    \n",
    "    return unique_images, unique_indices\n",
    "\n",
    "# Example usage:\n",
    "# list_of_pil_images = [...]\n",
    "unique_images, unique_indices = get_unique_images_with_indices(extracted_images)\n",
    "\n",
    "# Process the unique images\n",
    "processed_results = [img.height for img in unique_images]  # Replace with your actual processing\n",
    "\n",
    "# Map the results back to the original list\n",
    "original_results = [processed_results[i] for i in unique_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal-hybrid-parsing-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
