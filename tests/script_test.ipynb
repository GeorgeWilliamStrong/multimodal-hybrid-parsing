{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Optional, Union, Literal, Tuple\n",
    "from PIL import Image\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat, DocumentStream\n",
    "from docling.datamodel.pipeline_options import (\n",
    "    AcceleratorDevice,\n",
    "    AcceleratorOptions, \n",
    "    PdfPipelineOptions,\n",
    "    smolvlm_picture_description\n",
    ")\n",
    "from docling_core.types.doc import PictureItem\n",
    "import io\n",
    "import base64\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentProcessor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        device: Optional[str] = None,\n",
    "        num_threads: int = 8\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the processor\n",
    "\n",
    "        Args:\n",
    "            device: Device for processing ('cuda', 'mps', 'cpu', or 'auto'). \n",
    "                If None, will use 'auto'.\n",
    "            num_threads: Number of threads to use for processing\n",
    "            picture_description: Type of picture description to use:\n",
    "                - 'none': No picture description\n",
    "                - 'smolVLM': Lightweight vision-language model\n",
    "                - 'granite': Advanced vision-language model\n",
    "            images_scale: Scale factor for images (default: 300/72.0)\n",
    "        \"\"\"\n",
    "        device_map = {\n",
    "            \"cuda\": AcceleratorDevice.CUDA,\n",
    "            \"mps\": AcceleratorDevice.MPS, \n",
    "            \"cpu\": AcceleratorDevice.CPU,\n",
    "            \"auto\": AcceleratorDevice.AUTO,\n",
    "        }\n",
    "        \n",
    "        self.device = device or \"auto\"\n",
    "        if self.device not in device_map:\n",
    "            msg = f\"Invalid device '{device}'. Must be one of: {list(device_map.keys())}\"\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        self.pipeline_options = PdfPipelineOptions(artifacts_path=\"/Users/georgestrong/multimodal-hybrid-parsing/models/v0.1.0/docling-models\")\n",
    "        self.pipeline_options.images_scale = 300/72.0\n",
    "        self.pipeline_options.generate_page_images = True\n",
    "        self.pipeline_options.generate_picture_images = True\n",
    "        self.pipeline_options.accelerator_options = AcceleratorOptions(\n",
    "            num_threads=num_threads,\n",
    "            device=device_map[self.device]\n",
    "        )\n",
    "        self.pipeline_options.do_picture_description = True\n",
    "        prompt = \"Describe what you can see in this image. Focus only on what is visually present. Be concise and accurate in three sentences maximum.\"\n",
    "        self.pipeline_options.picture_description_options = smolvlm_picture_description\n",
    "        self.pipeline_options.picture_description_options.prompt = prompt\n",
    "        self.pipeline_options.picture_description_options.generation_config = {\n",
    "            \"max_new_tokens\": 500,\n",
    "            \"do_sample\": False,\n",
    "        }\n",
    "\n",
    "        self.converter = DocumentConverter(\n",
    "            format_options={\n",
    "                InputFormat.PDF: PdfFormatOption(\n",
    "                    pipeline_options=self.pipeline_options\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def __call__(\n",
    "        self, \n",
    "        file_path: Union[str, Path]\n",
    "    ) -> Tuple[List[str], List[Image.Image], List[Image.Image]]:\n",
    "        \"\"\"\n",
    "        Process a document and return markdown pages and images\n",
    "\n",
    "        Args:\n",
    "            file_path: Path to the PDF file\n",
    "\n",
    "        Returns:\n",
    "            Tuple containing:\n",
    "            - List of markdown strings (one per page)\n",
    "            - List of extracted images (figures/graphs)\n",
    "            - List of page images\n",
    "        \"\"\"\n",
    "        file_path = Path(file_path) if isinstance(file_path, str) else file_path\n",
    "\n",
    "        result = self.converter.convert(file_path)\n",
    "\n",
    "        page_images = []\n",
    "        extracted_images = []\n",
    "        markdown_pages = []\n",
    "        picture_descriptions = {}\n",
    "\n",
    "        # Get page images from the conversion result\n",
    "        for page_no, page in result.document.pages.items():\n",
    "            if hasattr(page, 'image') and page.image is not None:\n",
    "                page_images.append(page.image.pil_image)\n",
    "\n",
    "        # Collect images and descriptions\n",
    "        for element, _level in result.document.iterate_items():\n",
    "            if isinstance(element, PictureItem):\n",
    "                page_no = element.prov[0].page_no\n",
    "                \n",
    "                if hasattr(element, 'image') and element.image is not None:\n",
    "                    extracted_images.append(element.image.pil_image)\n",
    "                \n",
    "                if page_no not in picture_descriptions:\n",
    "                    picture_descriptions[page_no] = []\n",
    "                \n",
    "                if element.annotations:\n",
    "                    ann = element.annotations[0]\n",
    "                    desc = f\"**AI-Generated Image Description:** {ann.text}\\n<!-- end image description -->\"\n",
    "                    picture_descriptions[page_no].append(desc)\n",
    "\n",
    "        # Process markdown pages\n",
    "        for i in range(result.document.num_pages()):\n",
    "            page_no = i + 1\n",
    "            page_md = result.document.export_to_markdown(page_no=page_no)\n",
    "            \n",
    "            if page_no in picture_descriptions:\n",
    "                parts = page_md.split(\"<!-- image -->\")\n",
    "                new_page_md = parts[0]\n",
    "                \n",
    "                for idx, part in enumerate(parts[1:]):\n",
    "                    if idx < len(picture_descriptions[page_no]):\n",
    "                        description = picture_descriptions[page_no][idx]\n",
    "                        new_page_md += f\"<!-- image -->\\n{description}\\n{part}\"\n",
    "                    else:\n",
    "                        new_page_md += f\"<!-- image -->{part}\"\n",
    "                \n",
    "                page_md = new_page_md\n",
    "            \n",
    "            markdown_pages.append(page_md)\n",
    "\n",
    "        return markdown_pages, extracted_images, page_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentProcessor:\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):\n",
    "        self.pipeline_options = PdfPipelineOptions()\n",
    "        self.pipeline_options.images_scale = 300/72.0\n",
    "        self.pipeline_options.generate_page_images = True\n",
    "        self.pipeline_options.generate_picture_images = True\n",
    "        self.pipeline_options.accelerator_options = AcceleratorOptions(\n",
    "            num_threads=8,\n",
    "            device=AcceleratorDevice.CUDA\n",
    "        )\n",
    "        self.pipeline_options.do_picture_description = False\n",
    "        prompt = \"Describe what you can see in this image. Focus only on what is visually present. Be concise and accurate in three sentences maximum.\"\n",
    "        self.pipeline_options.picture_description_options = smolvlm_picture_description\n",
    "        self.pipeline_options.picture_description_options.prompt = prompt\n",
    "        self.pipeline_options.picture_description_options.generation_config = {\n",
    "            \"max_new_tokens\": 500,\n",
    "            \"do_sample\": False,\n",
    "        }\n",
    "\n",
    "        self.converter = DocumentConverter(\n",
    "            format_options={\n",
    "                InputFormat.PDF: PdfFormatOption(\n",
    "                    pipeline_options=self.pipeline_options\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def __call__(\n",
    "        self, \n",
    "        base64_content: str\n",
    "    ) -> Tuple[List[str], List[str], List[str]]:\n",
    "        \"\"\"\n",
    "        Process a document and return markdown pages and base64 encoded images\n",
    "\n",
    "        Args:\n",
    "            base64_content: Base64 encoded PDF file content\n",
    "\n",
    "        Returns:\n",
    "            Tuple containing:\n",
    "            - List of markdown strings (one per page)\n",
    "            - List of base64 encoded extracted images (figures/graphs)\n",
    "            - List of base64 encoded page images\n",
    "        \"\"\"\n",
    "        # Decode base64 content to bytes\n",
    "        pdf_content = base64.b64decode(base64_content)\n",
    "        \n",
    "        # Create BytesIO object and DocumentStream\n",
    "        pdf_stream = io.BytesIO(pdf_content)\n",
    "        source = DocumentStream(name=\"doc.pdf\", stream=pdf_stream)\n",
    "\n",
    "        # Convert using DocumentStream\n",
    "        result = self.converter.convert(source)\n",
    "\n",
    "        page_images = []\n",
    "        extracted_images = []\n",
    "        markdown_pages = []\n",
    "        picture_descriptions = {}\n",
    "\n",
    "        # Get page images from the conversion result\n",
    "        for page_no, page in result.document.pages.items():\n",
    "            if hasattr(page, 'image') and page.image is not None:\n",
    "                page_images.append(str(page.image.uri))\n",
    "\n",
    "        # Collect images and descriptions\n",
    "        for element, _level in result.document.iterate_items():\n",
    "            if isinstance(element, PictureItem):\n",
    "                page_no = element.prov[0].page_no\n",
    "                \n",
    "                if hasattr(element, 'image') and element.image is not None:\n",
    "                    extracted_images.append(str(element.image.uri))\n",
    "                \n",
    "                if page_no not in picture_descriptions:\n",
    "                    picture_descriptions[page_no] = []\n",
    "                \n",
    "                if element.annotations:\n",
    "                    ann = element.annotations[0]\n",
    "                    desc = f\"**AI-Generated Image Description:** {ann.text}\\n<!-- end image description -->\"\n",
    "                    picture_descriptions[page_no].append(desc)\n",
    "\n",
    "        # Process markdown pages\n",
    "        for i in range(result.document.num_pages()):\n",
    "            page_no = i + 1\n",
    "            page_md = result.document.export_to_markdown(page_no=page_no)\n",
    "            \n",
    "            if page_no in picture_descriptions:\n",
    "                parts = page_md.split(\"<!-- image -->\")\n",
    "                new_page_md = parts[0]\n",
    "                \n",
    "                for idx, part in enumerate(parts[1:]):\n",
    "                    if idx < len(picture_descriptions[page_no]):\n",
    "                        description = picture_descriptions[page_no][idx]\n",
    "                        new_page_md += f\"<!-- image -->\\n{description}\\n{part}\"\n",
    "                    else:\n",
    "                        new_page_md += f\"<!-- image -->{part}\"\n",
    "                \n",
    "                page_md = new_page_md\n",
    "            \n",
    "            markdown_pages.append(page_md)\n",
    "\n",
    "        return markdown_pages, extracted_images, page_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_processor = DocumentProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "with open(\"samples/[table] Black White Minimalist Simple Creative Freelancer Invoice (1).pdf\", 'rb') as pdf_file:\n",
    "    encoded_string = base64.b64encode(pdf_file.read())\n",
    "    base64_string = encoded_string.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"../models/v0.1.0/document_base64.txt\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    f.write('\"'+base64_string+'\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"../models/v0.1.0/sample_payload.json\"\n",
    "\n",
    "# Create a JSON payload\n",
    "payload = {\"pdf_content\": base64_string}\n",
    "\n",
    "# Write the JSON payload to a file\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(payload, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_pages, extracted_images, page_images = doc_processor(base64_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_processor = DocumentProcessor(\n",
    "    device=\"cpu\",\n",
    "    num_threads=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_pages, extracted_images, page_images = doc_processor(\"samples/[research-paper] 1312.6114v11.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'## Auto-Encoding Variational Bayes\\n\\nDiederik P. Kingma Machine Learning Group Universiteit van Amsterdam dpkingma@gmail.com\\n\\n## Max Welling\\n\\nMachine Learning Group Universiteit van Amsterdam welling.max@gmail.com\\n\\n## Abstract\\n\\nHow can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions are two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.\\n\\n## 1 Introduction\\n\\nHowcan we perform efficient approximate inference and learning with directed probabilistic models whose continuous latent variables and/or parameters have intractable posterior distributions? The variational Bayesian (VB) approach involves the optimization of an approximation to the intractable posterior. Unfortunately, the common mean-field approach requires analytical solutions of expectations w.r.t. the approximate posterior, which are also intractable in the general case. We show how a reparameterization of the variational lower bound yields a simple differentiable unbiased estimator of the lower bound; this SGVB (Stochastic Gradient Variational Bayes) estimator can be used for efficient approximate posterior inference in almost any model with continuous latent variables and/or parameters, and is straightforward to optimize using standard stochastic gradient ascent techniques.\\n\\nFor the case of an i.i.d. dataset and continuous latent variables per datapoint, we propose the AutoEncoding VB (AEVB) algorithm. In the AEVB algorithm we make inference and learning especially efficient by using the SGVB estimator to optimize a recognition model that allows us to perform very efficient approximate posterior inference using simple ancestral sampling, which in turn allows us to efficiently learn the model parameters, without the need of expensive iterative inference schemes (such as MCMC) per datapoint. The learned approximate posterior inference model can also be used for a host of tasks such as recognition, denoising, representation and visualization purposes. When a neural network is used for the recognition model, we arrive at the variational auto-encoder .\\n\\n## 2 Method\\n\\nThe strategy in this section can be used to derive a lower bound estimator (a stochastic objective function) for a variety of directed graphical models with continuous latent variables. We will restrict ourselves here to the common case where we have an i.i.d. dataset with latent variables per datapoint, and where we like to perform maximum likelihood (ML) or maximum a posteriori (MAP) inference on the (global) parameters, and variational inference on the latent variables. It is, for example,'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markdown_pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal-hybrid-parsing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
