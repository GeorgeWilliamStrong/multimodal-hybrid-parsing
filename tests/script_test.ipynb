{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/george/miniconda3/envs/multimodal-hybrid-parsing-2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Optional, Union, Literal, Tuple\n",
    "from PIL import Image\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat, DocumentStream\n",
    "from docling.datamodel.pipeline_options import (\n",
    "    AcceleratorDevice,\n",
    "    AcceleratorOptions, \n",
    "    PdfPipelineOptions,\n",
    "    smolvlm_picture_description\n",
    ")\n",
    "from docling_core.types.doc import PictureItem\n",
    "import io\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentProcessor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        device: Optional[str] = None,\n",
    "        num_threads: int = 8\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the processor\n",
    "\n",
    "        Args:\n",
    "            device: Device for processing ('cuda', 'mps', 'cpu', or 'auto'). \n",
    "                If None, will use 'auto'.\n",
    "            num_threads: Number of threads to use for processing\n",
    "            picture_description: Type of picture description to use:\n",
    "                - 'none': No picture description\n",
    "                - 'smolVLM': Lightweight vision-language model\n",
    "                - 'granite': Advanced vision-language model\n",
    "            images_scale: Scale factor for images (default: 300/72.0)\n",
    "        \"\"\"\n",
    "        device_map = {\n",
    "            \"cuda\": AcceleratorDevice.CUDA,\n",
    "            \"mps\": AcceleratorDevice.MPS, \n",
    "            \"cpu\": AcceleratorDevice.CPU,\n",
    "            \"auto\": AcceleratorDevice.AUTO,\n",
    "        }\n",
    "        \n",
    "        self.device = device or \"auto\"\n",
    "        if self.device not in device_map:\n",
    "            msg = f\"Invalid device '{device}'. Must be one of: {list(device_map.keys())}\"\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        self.pipeline_options = PdfPipelineOptions()\n",
    "        self.pipeline_options.images_scale = 300/72.0\n",
    "        self.pipeline_options.generate_page_images = True\n",
    "        self.pipeline_options.generate_picture_images = True\n",
    "        self.pipeline_options.accelerator_options = AcceleratorOptions(\n",
    "            num_threads=num_threads,\n",
    "            device=device_map[self.device]\n",
    "        )\n",
    "        self.pipeline_options.do_picture_description = True\n",
    "        prompt = \"Describe what you can see in this image. Focus only on what is visually present. Be concise and accurate in three sentences maximum.\"\n",
    "        self.pipeline_options.picture_description_options = smolvlm_picture_description\n",
    "        self.pipeline_options.picture_description_options.prompt = prompt\n",
    "        self.pipeline_options.picture_description_options.generation_config = {\n",
    "            \"max_new_tokens\": 500,\n",
    "            \"do_sample\": False,\n",
    "        }\n",
    "\n",
    "        self.converter = DocumentConverter(\n",
    "            format_options={\n",
    "                InputFormat.PDF: PdfFormatOption(\n",
    "                    pipeline_options=self.pipeline_options\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def __call__(\n",
    "        self, \n",
    "        file_path: Union[str, Path]\n",
    "    ) -> Tuple[List[str], List[Image.Image], List[Image.Image]]:\n",
    "        \"\"\"\n",
    "        Process a document and return markdown pages and images\n",
    "\n",
    "        Args:\n",
    "            file_path: Path to the PDF file\n",
    "\n",
    "        Returns:\n",
    "            Tuple containing:\n",
    "            - List of markdown strings (one per page)\n",
    "            - List of extracted images (figures/graphs)\n",
    "            - List of page images\n",
    "        \"\"\"\n",
    "        file_path = Path(file_path) if isinstance(file_path, str) else file_path\n",
    "\n",
    "        result = self.converter.convert(file_path)\n",
    "\n",
    "        page_images = []\n",
    "        extracted_images = []\n",
    "        markdown_pages = []\n",
    "        picture_descriptions = {}\n",
    "\n",
    "        # Get page images from the conversion result\n",
    "        for page_no, page in result.document.pages.items():\n",
    "            if hasattr(page, 'image') and page.image is not None:\n",
    "                page_images.append(page.image.pil_image)\n",
    "\n",
    "        # Collect images and descriptions\n",
    "        for element, _level in result.document.iterate_items():\n",
    "            if isinstance(element, PictureItem):\n",
    "                page_no = element.prov[0].page_no\n",
    "                \n",
    "                if hasattr(element, 'image') and element.image is not None:\n",
    "                    extracted_images.append(element.image.pil_image)\n",
    "                \n",
    "                if page_no not in picture_descriptions:\n",
    "                    picture_descriptions[page_no] = []\n",
    "                \n",
    "                if element.annotations:\n",
    "                    ann = element.annotations[0]\n",
    "                    desc = f\"**AI-Generated Image Description:** {ann.text}\\n<!-- end image description -->\"\n",
    "                    picture_descriptions[page_no].append(desc)\n",
    "\n",
    "        # Process markdown pages\n",
    "        for i in range(result.document.num_pages()):\n",
    "            page_no = i + 1\n",
    "            page_md = result.document.export_to_markdown(page_no=page_no)\n",
    "            \n",
    "            if page_no in picture_descriptions:\n",
    "                parts = page_md.split(\"<!-- image -->\")\n",
    "                new_page_md = parts[0]\n",
    "                \n",
    "                for idx, part in enumerate(parts[1:]):\n",
    "                    if idx < len(picture_descriptions[page_no]):\n",
    "                        description = picture_descriptions[page_no][idx]\n",
    "                        new_page_md += f\"<!-- image -->\\n{description}\\n{part}\"\n",
    "                    else:\n",
    "                        new_page_md += f\"<!-- image -->{part}\"\n",
    "                \n",
    "                page_md = new_page_md\n",
    "            \n",
    "            markdown_pages.append(page_md)\n",
    "\n",
    "        return markdown_pages, extracted_images, page_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentProcessor:\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):\n",
    "        self.pipeline_options = PdfPipelineOptions()\n",
    "        self.pipeline_options.images_scale = 300/72.0\n",
    "        self.pipeline_options.generate_page_images = True\n",
    "        self.pipeline_options.generate_picture_images = True\n",
    "        self.pipeline_options.accelerator_options = AcceleratorOptions(\n",
    "            num_threads=8,\n",
    "            device=AcceleratorDevice.CUDA\n",
    "        )\n",
    "        self.pipeline_options.do_picture_description = False\n",
    "        prompt = \"Describe what you can see in this image. Focus only on what is visually present. Be concise and accurate in three sentences maximum.\"\n",
    "        self.pipeline_options.picture_description_options = smolvlm_picture_description\n",
    "        self.pipeline_options.picture_description_options.prompt = prompt\n",
    "        self.pipeline_options.picture_description_options.generation_config = {\n",
    "            \"max_new_tokens\": 500,\n",
    "            \"do_sample\": False,\n",
    "        }\n",
    "\n",
    "        self.converter = DocumentConverter(\n",
    "            format_options={\n",
    "                InputFormat.PDF: PdfFormatOption(\n",
    "                    pipeline_options=self.pipeline_options\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def __call__(\n",
    "        self, \n",
    "        base64_content: str\n",
    "    ):#) -> Tuple[List[str], List[str], List[str]]:\n",
    "        \"\"\"\n",
    "        Process a document and return markdown pages and base64 encoded images\n",
    "\n",
    "        Args:\n",
    "            base64_content: Base64 encoded PDF file content\n",
    "\n",
    "        Returns:\n",
    "            Tuple containing:\n",
    "            - List of markdown strings (one per page)\n",
    "            - List of base64 encoded extracted images (figures/graphs)\n",
    "            - List of base64 encoded page images\n",
    "        \"\"\"\n",
    "        # Decode base64 content to bytes\n",
    "        pdf_content = base64.b64decode(base64_content)\n",
    "        \n",
    "        # Create BytesIO object and DocumentStream\n",
    "        pdf_stream = io.BytesIO(pdf_content)\n",
    "        source = DocumentStream(name=\"doc.pdf\", stream=pdf_stream)\n",
    "\n",
    "        # Convert using DocumentStream\n",
    "        result = self.converter.convert(source)\n",
    "\n",
    "        page_images = []\n",
    "        extracted_images = []\n",
    "        markdown_pages = []\n",
    "        picture_descriptions = {}\n",
    "\n",
    "        # Get page images from the conversion result\n",
    "        for page_no, page in result.document.pages.items():\n",
    "            if hasattr(page, 'image') and page.image is not None:\n",
    "                page_images.append(str(page.image.uri))\n",
    "\n",
    "        # Collect images and descriptions\n",
    "        for element, _level in result.document.iterate_items():\n",
    "            if isinstance(element, PictureItem):\n",
    "                page_no = element.prov[0].page_no\n",
    "                \n",
    "                if hasattr(element, 'image') and element.image is not None:\n",
    "                    extracted_images.append(str(element.image.uri))\n",
    "                \n",
    "                if page_no not in picture_descriptions:\n",
    "                    picture_descriptions[page_no] = []\n",
    "                \n",
    "                if element.annotations:\n",
    "                    ann = element.annotations[0]\n",
    "                    desc = f\"**AI-Generated Image Description:** {ann.text}\\n<!-- end image description -->\"\n",
    "                    picture_descriptions[page_no].append(desc)\n",
    "\n",
    "        # Process markdown pages\n",
    "        for i in range(result.document.num_pages()):\n",
    "            page_no = i + 1\n",
    "            page_md = result.document.export_to_markdown(page_no=page_no)\n",
    "            \n",
    "            if page_no in picture_descriptions:\n",
    "                parts = page_md.split(\"<!-- image -->\")\n",
    "                new_page_md = parts[0]\n",
    "                \n",
    "                for idx, part in enumerate(parts[1:]):\n",
    "                    if idx < len(picture_descriptions[page_no]):\n",
    "                        description = picture_descriptions[page_no][idx]\n",
    "                        new_page_md += f\"<!-- image -->\\n{description}\\n{part}\"\n",
    "                    else:\n",
    "                        new_page_md += f\"<!-- image -->{part}\"\n",
    "                \n",
    "                page_md = new_page_md\n",
    "            \n",
    "            markdown_pages.append(page_md)\n",
    "\n",
    "        return markdown_pages, extracted_images, page_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_processor = DocumentProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "with open(\"samples/[research-paper] 1312.6114v11.pdf\", 'rb') as pdf_file:\n",
    "    encoded_string = base64.b64encode(pdf_file.read())\n",
    "    base64_string = encoded_string.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/george/miniconda3/envs/multimodal-hybrid-parsing-2/lib/python3.12/site-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "markdown_pages, extracted_images, page_images = doc_processor(base64_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_processor = DocumentProcessor(\n",
    "    device=\"cpu\",\n",
    "    num_threads=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_pages, extracted_images, page_images = doc_processor(\"samples/[research-paper] 1312.6114v11.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal-hybrid-parsing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
