{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/george/miniconda3/envs/multimodal-hybrid-parsing-2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Optional, Union, Literal, Tuple, Any\n",
    "from PIL import Image\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat, DocumentStream\n",
    "from docling.datamodel.pipeline_options import (\n",
    "    AcceleratorDevice,\n",
    "    AcceleratorOptions, \n",
    "    PdfPipelineOptions,\n",
    "    smolvlm_picture_description\n",
    ")\n",
    "from docling_core.types.doc import PictureItem\n",
    "import io\n",
    "import base64\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentProcessor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        device: Optional[str] = None,\n",
    "        num_threads: int = 8\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the processor\n",
    "\n",
    "        Args:\n",
    "            device: Device for processing ('cuda', 'mps', 'cpu', or 'auto'). \n",
    "                If None, will use 'auto'.\n",
    "            num_threads: Number of threads to use for processing\n",
    "            picture_description: Type of picture description to use:\n",
    "                - 'none': No picture description\n",
    "                - 'smolVLM': Lightweight vision-language model\n",
    "                - 'granite': Advanced vision-language model\n",
    "            images_scale: Scale factor for images (default: 300/72.0)\n",
    "        \"\"\"\n",
    "        device_map = {\n",
    "            \"cuda\": AcceleratorDevice.CUDA,\n",
    "            \"mps\": AcceleratorDevice.MPS, \n",
    "            \"cpu\": AcceleratorDevice.CPU,\n",
    "            \"auto\": AcceleratorDevice.AUTO,\n",
    "        }\n",
    "        \n",
    "        self.device = device or \"auto\"\n",
    "        if self.device not in device_map:\n",
    "            msg = f\"Invalid device '{device}'. Must be one of: {list(device_map.keys())}\"\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        self.pipeline_options = PdfPipelineOptions()\n",
    "        self.pipeline_options.images_scale = 300/72.0\n",
    "        self.pipeline_options.generate_page_images = True\n",
    "        self.pipeline_options.generate_picture_images = True\n",
    "        self.pipeline_options.do_formula_enrichment = True\n",
    "        self.pipeline_options.accelerator_options = AcceleratorOptions(\n",
    "            num_threads=num_threads,\n",
    "            device=device_map[self.device]\n",
    "        )\n",
    "        self.pipeline_options.do_picture_description = False\n",
    "        prompt = \"Describe what you can see in this image. Focus only on what is visually present. Be concise and accurate in three sentences maximum.\"\n",
    "        self.pipeline_options.picture_description_options = smolvlm_picture_description\n",
    "        self.pipeline_options.picture_description_options.prompt = prompt\n",
    "        self.pipeline_options.picture_description_options.generation_config = {\n",
    "            \"max_new_tokens\": 500,\n",
    "            \"do_sample\": False,\n",
    "        }\n",
    "\n",
    "        self.converter = DocumentConverter(\n",
    "            format_options={\n",
    "                InputFormat.PDF: PdfFormatOption(\n",
    "                    pipeline_options=self.pipeline_options\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def __call__(\n",
    "        self, \n",
    "        file_path: Union[str, Path]\n",
    "    ) -> Tuple[List[str], List[Image.Image], List[Image.Image]]:\n",
    "        \"\"\"\n",
    "        Process a document and return markdown pages and images\n",
    "\n",
    "        Args:\n",
    "            file_path: Path to the PDF file\n",
    "\n",
    "        Returns:\n",
    "            Tuple containing:\n",
    "            - List of markdown strings (one per page)\n",
    "            - List of extracted images (figures/graphs)\n",
    "            - List of page images\n",
    "        \"\"\"\n",
    "        file_path = Path(file_path) if isinstance(file_path, str) else file_path\n",
    "\n",
    "        result = self.converter.convert(file_path)\n",
    "\n",
    "        page_images = []\n",
    "        extracted_images = []\n",
    "        markdown_pages = []\n",
    "        picture_descriptions = {}\n",
    "\n",
    "        # Get page images from the conversion result\n",
    "        for page_no, page in result.document.pages.items():\n",
    "            if hasattr(page, 'image') and page.image is not None:\n",
    "                page_images.append(page.image.pil_image)\n",
    "\n",
    "        # Collect images and descriptions\n",
    "        for element, _level in result.document.iterate_items():\n",
    "            if isinstance(element, PictureItem):\n",
    "                page_no = element.prov[0].page_no\n",
    "                \n",
    "                if hasattr(element, 'image') and element.image is not None:\n",
    "                    extracted_images.append(element.image.pil_image)\n",
    "                \n",
    "                if page_no not in picture_descriptions:\n",
    "                    picture_descriptions[page_no] = []\n",
    "                \n",
    "                if element.annotations:\n",
    "                    ann = element.annotations[0]\n",
    "                    desc = f\"**AI-Generated Image Description:** {ann.text}\\n<!-- end image description -->\"\n",
    "                    picture_descriptions[page_no].append(desc)\n",
    "\n",
    "        # Process markdown pages\n",
    "        for i in range(result.document.num_pages()):\n",
    "            page_no = i + 1\n",
    "            page_md = result.document.export_to_markdown(page_no=page_no)\n",
    "            \n",
    "            if page_no in picture_descriptions:\n",
    "                parts = page_md.split(\"<!-- image -->\")\n",
    "                new_page_md = parts[0]\n",
    "                \n",
    "                for idx, part in enumerate(parts[1:]):\n",
    "                    if idx < len(picture_descriptions[page_no]):\n",
    "                        description = picture_descriptions[page_no][idx]\n",
    "                        new_page_md += f\"<!-- image -->\\n{description}\\n{part}\"\n",
    "                    else:\n",
    "                        new_page_md += f\"<!-- image -->{part}\"\n",
    "                \n",
    "                page_md = new_page_md\n",
    "            \n",
    "            markdown_pages.append(page_md)\n",
    "\n",
    "        return markdown_pages, extracted_images, page_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentProcessor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        device: Optional[str] = None,\n",
    "        num_threads: int = 8\n",
    "    ):\n",
    "        device_map = {\n",
    "            \"cuda\": AcceleratorDevice.CUDA,\n",
    "            \"mps\": AcceleratorDevice.MPS, \n",
    "            \"cpu\": AcceleratorDevice.CPU,\n",
    "            \"auto\": AcceleratorDevice.AUTO,\n",
    "        }\n",
    "\n",
    "        self.device = device or \"auto\"\n",
    "        if self.device not in device_map:\n",
    "            msg = f\"Invalid device '{device}'. Must be one of: {list(device_map.keys())}\"\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        self.pipeline_options = PdfPipelineOptions()\n",
    "        self.pipeline_options.images_scale = 150/72.0\n",
    "        self.pipeline_options.generate_page_images = True\n",
    "        self.pipeline_options.generate_picture_images = True\n",
    "        self.pipeline_options.do_formula_enrichment = True\n",
    "        self.pipeline_options.accelerator_options = AcceleratorOptions(\n",
    "            num_threads=num_threads,\n",
    "            device=device_map[self.device]\n",
    "        )\n",
    "        self.pipeline_options.do_picture_description = False\n",
    "\n",
    "        self.converter = DocumentConverter(\n",
    "            format_options={\n",
    "                InputFormat.PDF: PdfFormatOption(\n",
    "                    pipeline_options=self.pipeline_options\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def __call__(\n",
    "        self, \n",
    "        file_path: Union[str, Path]\n",
    "    ) -> Tuple[List[str], List[Image.Image], List[Image.Image]]:\n",
    "        file_path = Path(file_path) if isinstance(file_path, str) else file_path\n",
    "\n",
    "        result = self.converter.convert(file_path)\n",
    "\n",
    "        extracted_images = []\n",
    "        markdown_pages = []\n",
    "        pages_with_images = []\n",
    "\n",
    "        # Extract images\n",
    "        for element, _level in result.document.iterate_items():\n",
    "            if isinstance(element, PictureItem):\n",
    "                page_no = element.prov[0].page_no\n",
    "\n",
    "                if hasattr(element, 'image') and element.image is not None:\n",
    "                    extracted_images.append(element.image.pil_image)\n",
    "                    if page_no not in pages_with_images:\n",
    "                        pages_with_images.append(page_no)\n",
    "\n",
    "        # Process markdown pages\n",
    "        for page in range(result.document.num_pages()):\n",
    "            page_no = page + 1\n",
    "            page_md = result.document.export_to_markdown(page_no=page_no)\n",
    "            markdown_pages.append(page_md)\n",
    "\n",
    "        return markdown_pages, extracted_images, pages_with_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentProcessor:\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):\n",
    "        self.pipeline_options = PdfPipelineOptions()\n",
    "        self.pipeline_options.images_scale = 300/72.0\n",
    "        self.pipeline_options.generate_page_images = True\n",
    "        self.pipeline_options.generate_picture_images = True\n",
    "        self.pipeline_options.do_formula_enrichment = True\n",
    "        self.pipeline_options.accelerator_options = AcceleratorOptions(\n",
    "            num_threads=8,\n",
    "            device=AcceleratorDevice.CUDA\n",
    "        )\n",
    "        self.pipeline_options.do_picture_description = False\n",
    "        prompt = \"Describe what you can see in this image. Focus only on what is visually present. Be concise and accurate in three sentences maximum.\"\n",
    "        self.pipeline_options.picture_description_options = smolvlm_picture_description\n",
    "        self.pipeline_options.picture_description_options.prompt = prompt\n",
    "        self.pipeline_options.picture_description_options.generation_config = {\n",
    "            \"max_new_tokens\": 500,\n",
    "            \"do_sample\": False,\n",
    "        }\n",
    "\n",
    "        self.converter = DocumentConverter(\n",
    "            format_options={\n",
    "                InputFormat.PDF: PdfFormatOption(\n",
    "                    pipeline_options=self.pipeline_options\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def __call__(\n",
    "        self, \n",
    "        base64_content: str\n",
    "    ) -> Tuple[List[str], List[str], List[str]]:\n",
    "        \"\"\"\n",
    "        Process a document and return markdown pages and base64 encoded images\n",
    "\n",
    "        Args:\n",
    "            base64_content: Base64 encoded PDF file content\n",
    "\n",
    "        Returns:\n",
    "            Tuple containing:\n",
    "            - List of markdown strings (one per page)\n",
    "            - List of base64 encoded extracted images (figures/graphs)\n",
    "            - List of base64 encoded page images\n",
    "        \"\"\"\n",
    "        # Decode base64 content to bytes\n",
    "        pdf_content = base64.b64decode(base64_content)\n",
    "        \n",
    "        # Create BytesIO object and DocumentStream\n",
    "        pdf_stream = io.BytesIO(pdf_content)\n",
    "        source = DocumentStream(name=\"doc.pdf\", stream=pdf_stream)\n",
    "\n",
    "        # Convert using DocumentStream\n",
    "        result = self.converter.convert(source)\n",
    "\n",
    "        page_images = []\n",
    "        extracted_images = []\n",
    "        markdown_pages = []\n",
    "        picture_descriptions = {}\n",
    "\n",
    "        # Get page images from the conversion result\n",
    "        for page_no, page in result.document.pages.items():\n",
    "            if hasattr(page, 'image') and page.image is not None:\n",
    "                page_images.append(str(page.image.uri))\n",
    "\n",
    "        # Collect images and descriptions\n",
    "        for element, _level in result.document.iterate_items():\n",
    "            if isinstance(element, PictureItem):\n",
    "                page_no = element.prov[0].page_no\n",
    "                \n",
    "                if hasattr(element, 'image') and element.image is not None:\n",
    "                    extracted_images.append(str(element.image.uri))\n",
    "                \n",
    "                if page_no not in picture_descriptions:\n",
    "                    picture_descriptions[page_no] = []\n",
    "                \n",
    "                if element.annotations:\n",
    "                    ann = element.annotations[0]\n",
    "                    desc = f\"**AI-Generated Image Description:** {ann.text}\\n<!-- end image description -->\"\n",
    "                    picture_descriptions[page_no].append(desc)\n",
    "\n",
    "        # Process markdown pages\n",
    "        for i in range(result.document.num_pages()):\n",
    "            page_no = i + 1\n",
    "            page_md = result.document.export_to_markdown(page_no=page_no)\n",
    "            \n",
    "            if page_no in picture_descriptions:\n",
    "                parts = page_md.split(\"<!-- image -->\")\n",
    "                new_page_md = parts[0]\n",
    "                \n",
    "                for idx, part in enumerate(parts[1:]):\n",
    "                    if idx < len(picture_descriptions[page_no]):\n",
    "                        description = picture_descriptions[page_no][idx]\n",
    "                        new_page_md += f\"<!-- image -->\\n{description}\\n{part}\"\n",
    "                    else:\n",
    "                        new_page_md += f\"<!-- image -->{part}\"\n",
    "                \n",
    "                page_md = new_page_md\n",
    "            \n",
    "            markdown_pages.append(page_md)\n",
    "\n",
    "        return markdown_pages, extracted_images, page_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_processor = DocumentProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "with open(\"samples/[table] Black White Minimalist Simple Creative Freelancer Invoice (1).pdf\", 'rb') as pdf_file:\n",
    "    encoded_string = base64.b64encode(pdf_file.read())\n",
    "    base64_string = encoded_string.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"../models/v0.1.0/document_base64.txt\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    f.write('\"'+base64_string+'\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"../models/v0.1.0/sample_payload.json\"\n",
    "\n",
    "# Create a JSON payload\n",
    "payload = {\"pdf_content\": base64_string}\n",
    "\n",
    "# Write the JSON payload to a file\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(payload, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_pages, extracted_images, page_images = doc_processor(base64_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_processor = DocumentProcessor(\n",
    "    device=\"cuda\",\n",
    "    num_threads=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_pages, extracted_images, pages_with_images = doc_processor(\"samples/sample.pptx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Harnessing High Frequency Data To Inform Development and Humanitarian Interventions\\n\\nChristopher B. Barrett\\n\\nKeynote address to the World Bank conference\\n\\nThe Pulse of Progress: Harnessing High-Frequency Survey Data for Development Research in the Polycrisis Era\\n\\nWashington, DC\\n\\nDecember 17, 2024\\n\\n<!-- image -->',\n",
       " 'Statistically representative observational data essential for accurate descriptive/predictive analysis. Often useful for inferential analysis.\\n\\nWorld Bank established LSMS &gt;40 years ago for comparable measurement of living standards defined broadly. With improved measurement came improved analysis. \\n\\n\\t\\t\\t\\t– Angus Deaton 1997 (and 2018)\\n\\n“To direct scarce resources to where they can do the greatest good, actions must be guided by reliable information … Measurement drives diagnosis and response. ” \\n\\n\\t\\t\\t\\t– Barrett (Science 2010)\\n\\n<!-- image -->\\n\\nWhy national survey data?\\n\\n<!-- image -->\\n\\n<!-- image -->',\n",
       " 'Living standards are dynamic. A solid understanding of dynamic living standards requires HFL data.\\n\\n1. Differentiating chronic vs. transitory state (poverty/food insecurity/ill health) matters fundamentally to policy design and evaluation. \\n\\n2. Seasonality looms large for the poor (esp. rural poor). Surveys every few years either miss seasonality or create seasonal mismatch issues in intertemporal comparison. \\n\\n<!-- image -->\\n\\nWhy high-frequency longitudinal (HFL) national survey data?\\n\\n<!-- image -->\\n\\n<!-- image -->\\n\\nSource: Barrett &amp; Headey (IFPRI 2014) using data from Bloem et al. (HKI 2003)\\n\\nChild wasting in Bangladesh',\n",
       " '3. Dynamics introduce risk and uncertainty. It’s hard to understand human behavior and well-being without explicitly considering risk. \\n\\n- Risk aversion and defensive actions/investments\\n- Non-stationarity and shocks\\n- FE estimators –true intertemporal change; time invariant unobservables.\\n- Improve external validity – Rosenzweig &amp; Udry (REStudies 2020)\\n\\n\\t▪ moments beyond the mean matter to behavior and well-being.\\n\\n\\t▪ inference commonly assumes stationary DGPs\\n\\n4. Improved inference about what causes change in living standards. \\n\\n<!-- image -->\\n\\nWhy high-frequency longitudinal (HFL) national survey data?',\n",
       " 'HFL data esp. important amid polycrisis. Multivariate risks growing: weather, conflict, prices, pandemics, etc. Solid inference around effective interventions crucial. Must parse chronic/seasonal/transitory effects of shocks.\\n\\nDistinction b/n s-run humanitarian and longer-run development interventions is increasingly blurred,       esp. in low-income settings. \\n\\nHence attention to ‘resilience’ = shock-proofing continuous improvement in living standards.\\n\\n<!-- image -->\\n\\nPolycrisis era\\n\\n<!-- image -->\\n\\n<!-- image -->',\n",
       " '<!-- image -->\\n\\nPolycrisis, poverty traps, and resilience\\n\\n<!-- image -->\\n\\npoverty line\\n\\nPoverty traps increasingly understood as arising due to catastrophic risk exposure and/or the experience of catastrophic shocks. Reasonable theory exists, rooting resilience in living standards.\\n\\n<!-- image -->\\n\\n<!-- image -->\\n\\n<!-- image -->\\n\\n<!-- image -->',\n",
       " '<!-- image -->\\n\\n“our empirical understanding of development resilience in developing countries remains remarkably limited, primarily because of data shortcomings. … [The world needs] a multicountry system of high-frequency, long-term sentinel sites in the world’s most vulnerable (and largely rural) regions. … In an increasingly volatile world, good data are essential. Such data will help the global community build development resilience and eliminate hunger, extreme poverty, and vulnerability in the generation ahead.”\\n\\nHFL survey data especially important for studying resilience. \\n\\n<!-- image -->\\n\\n<!-- image -->\\n\\n<!-- image -->\\n\\nYet very scarce. Scoping review of ‘resilience’ studies 2008-2020 found just 16% used panel data at all, much less HF!        (Barrett et al. WD 2021)\\n\\nResilience measurement',\n",
       " '<!-- image -->\\n\\nResilience – like poverty, food security, women’s empowerment – is a latent variable … inherently hard to measure. Takes time to create/validate good measures of latent variables. Not yet there for resilience measurement.  \\n\\nCore issues: \\n\\n1. Interventions aim to ‘build resilience’, thus measures must allow resilience to be a dependent variable and to carry normative implications (e.g., monotonicity). \\n2. Must work with multiple perils, given multivariate risk exposure.\\n3. Must be decomposable since subpopulations may be heterogeneous.\\n4. Given pronounced behavioral response to risk, must account for ex ante risk exposure not just ex post experience of shocks. \\n5. Measures remain contested, imprecise, and inconsistent (Upton, Cissé &amp; Barrett Ag Econ 2016; Cissé &amp; Barrett JDE 2018; Barrett et al. WD 2021; Upton, Constenla-Villoslada &amp; Barrett JDE 2022)\\n\\nMore and better resilience measurement research is needed.\\n\\nResilience measurement',\n",
       " 'The dearth of HFL socioeconomic survey data motivates enthusiasm for HFL geospatial data and ML algorithms to generate nowcasts/forecasts:\\n\\n“\\xa0a given African household will appear in a household well-being survey less than once every 1000 years” – Yeh et al. (Nature Communications 2020)\\n\\nMachine learning is indeed very promising, esp. for data fusion. \\n\\n(Yeh et al. NC 2020; McBride et al. AEPP 2022; Gualavisi &amp; Newhouse WBER 2024; Newhouse CSAB 2024)\\n\\nExample: spatial imagery + survey data permit pixel-scale wealth predictions at scale and downstream targeting. (Yeh et al. NC 2020, Figs 5-6 below)\\n\\n<!-- image -->\\n\\nBenefits/Limits to Machine Learning\\n\\n<!-- image -->\\n\\n<!-- image -->',\n",
       " 'But HFL EO data complement, not substitute, for HFL SE data. Opportunities arising from ML and VHR/HF geospatial data boost need for HFL SE data.\\n\\n2. ML models need lots of good, reasonably current training data, ideally HFL SE data. Nonstationarity is a fundamental challenge, even to nowcasting. (Browne et al. PLoS ONE 2021; Constenla et al. in review; Tennant et al. in review).\\n3. Prone to atheoretic modeling (McBride et al. AEPP 2022)\\n4. Frequent, large bias – focus on OOS predictive skill overall. Misses significant spatial/livelihood heterogeneity, esp. related to unobservables and non-classical measurement error. (Ru et al. in review; Tennant et al. in review)\\n5. Reproducibility harder than conventional econometric/statistical work. \\n6. Often too technical and high-cost for operational agencies.\\n\\n<!-- image -->\\n\\nBenefits/Limits to Machine Learning',\n",
       " 'Rapid response ≠ researchers’ comparative advantage. We must improve our ability to respond to sudden changes. \\n\\nHFL SE survey data can not only: \\n\\n- improve ability to describe dynamics and risk\\n- do better inference \\n- add value to HFL geospatial data and ML\\n\\nHFL SE survey data can also enable analytical tasks that researchers undersupply currently.\\n\\n<!-- image -->\\n\\nWhat role for HFL survey data in polycrisis era?',\n",
       " 'Use to design interventions that can build resilience. \\n\\nExample: index-based livestock insurance (IBLI)\\n\\n- HFL survey data enabled original IBLI design and piloting. (Chantarat et al. JRI 2013)\\n- Enabled quasi-experimental comparison of IBLI vs. cash transfers. (Jensen et al. JDE 2017)\\n- End result: IBLI scaled from pilot in small parts of 2 countries to broader use in 4 (and growing: Kenya Livestock Insurance Program, DRIVE).  ~600K people covered to date, expected/targeted &gt;1.5M by end-2025. \\n\\n<!-- image -->\\n\\n<!-- image -->\\n\\n<!-- image -->\\n\\n<!-- image -->\\n\\nPilot areas\\n\\nWhat role for HFL survey data in polycrisis era?',\n",
       " 'Use for early warning and geographic targeting\\n\\n<!-- image -->\\n\\nWhat role for HFL survey data in polycrisis era?\\n\\nMost empirical economic analysis inherently backward looking; policy advice is forward-looking. HFL survey data allow for (i) rapid updating, (ii) nowcasting/forecasting for early warning and geographic targeting. High value of high frequency sentinel site data (Constenla et al. in review).\\n\\n<!-- image -->',\n",
       " 'In polycrisis era, HFL survey data are more valuable than ever. Help answer policymakers’ questions in face of growing risk and shocks: \\n\\n- What gains from emergency preparedness? Behavioral responses to risk/shocks measured right.\\n- What benefits from response to shocks? Transitory vs. seasonal vs. chronic and possibility of poverty traps. Inference using ‘within’ variation.\\n- Where and when to respond? Nowcasting/forecasting maps\\n- How to customized bundled responses? Sufficient variation in sites to identify heterogeneous and interaction effects. \\n\\n- Which tool(s) to use? More A/B testing, less H0=0 testing. Test under varied states of nature.\\n\\nResearchers have lots to do to help build resilience to polycrisis!\\n\\n<!-- image -->\\n\\nWhy high-frequency longitudinal (HFL) national survey data?',\n",
       " 'Thank you for your time and interest!\\n\\nFollow-up questions/comments? \\n\\nEmail me: cbb2@cornell.edu\\n\\n<!-- image -->\\n\\nThank you']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markdown_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_images[0] == extracted_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(markdown_pages[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_images[0].save(\"test0.png\")\n",
    "extracted_images[1].save(\"test1.png\")\n",
    "extracted_images[2].save(\"test2.png\")\n",
    "extracted_images[3].save(\"test3.png\")\n",
    "extracted_images[4].save(\"test4.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for i in extracted_images:\n",
    "    i.save(f\"test{counter}.png\")\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal-hybrid-parsing-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
